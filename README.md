# Static-web-Scraper
This project is a full-stack web application designed for administratively managing book data scraped from a static website. The backend is built using Node.js with Express, connected to MongoDB for storing book data, and integrates Python for the actual web scraping logic. The frontend is developed using React with Bootstrap and React-Toastify for notifications. The admin dashboard provides three main functionalities: Scrape Now, Get Books, and Delete All, allowing the admin to control the scraping process, fetch stored book entries, or clear the database. The scraping is handled by a Python script using BeautifulSoup and Requests, which is triggered via an API call and fetches book details like title, price, availability, and rating.

Authentication is secured using JWT (JSON Web Tokens), and all API routes require a valid token, stored in the browser’s localStorage. During the scraping process, a loader with a message ("Please wait 5–10 minutes") keeps the admin informed, and all actions provide feedback via toasts. The frontend makes secure API calls to routes like /api/books/scrape, /api/books/get, and /api/books/delete, all protected using bearer tokens. Errors and statuses are managed gracefully, providing a clean and professional user experience.

The backend requires Python dependencies such as requests, beautifulsoup4, pymongo, and python-dotenv, ideally installed inside a Python virtual environment. On the server, PM2 is used to manage the backend process, and logs are monitored for errors like Python execution issues or missing modules. The frontend runs on a custom port and hosted on a VM 
